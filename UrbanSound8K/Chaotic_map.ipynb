{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6cadb-f7ac-40b0-a551-795e4b085c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Memory-Efficient Chaotic Map Comparison...\n",
      "üí° Using block processing to avoid memory issues...\n",
      "üéµ Loading: UrbanSound8K/any_wav.wav\n",
      "üìä Processing: 88200 samples, 44100 Hz\n",
      "\n",
      "==================================================\n",
      "üß™ Testing LOGISTIC\n",
      "==================================================\n",
      "\n",
      "üéµ Applying LOGISTIC Chaotic Compression...\n",
      "   DWT level: 4\n",
      "   Coefficients: 88227 ‚Üí 44113 (Compression: 50.0%)\n",
      "   Block compression progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shyam\\AppData\\Local\\Temp\\ipykernel_17280\\3461649354.py:95: RuntimeWarning: invalid value encountered in dot\n",
      "  block_measurements[j] = np.dot(chaotic_vector, coeffs_flat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1000/44113 measurements completed\n",
      "      6000/44113 measurements completed\n",
      "      11000/44113 measurements completed\n",
      "      16000/44113 measurements completed\n",
      "      21000/44113 measurements completed\n",
      "      26000/44113 measurements completed\n",
      "      31000/44113 measurements completed\n",
      "      36000/44113 measurements completed\n",
      "      41000/44113 measurements completed\n",
      "   Reconstruction using gradient method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shyam\\AppData\\Local\\Temp\\ipykernel_17280\\3461649354.py:128: RuntimeWarning: invalid value encountered in dot\n",
      "  y_pred = np.dot(chaotic_vector, x_reconstructed)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "class BlockChaoticDWTCompressedSensing:\n",
    "    def __init__(self, wavelet='db4', compression_ratio=0.5, chaotic_map='logistic'):\n",
    "        self.wavelet = wavelet\n",
    "        self.compression_ratio = compression_ratio\n",
    "        self.chaotic_map = chaotic_map\n",
    "        \n",
    "    def generate_chaotic_vector(self, length, seed=0):\n",
    "        \"\"\"Generate chaotic sequence without storing large matrix\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if self.chaotic_map == 'logistic':\n",
    "            # Logistic map\n",
    "            sequence = []\n",
    "            x = 0.1 + seed * 0.01\n",
    "            r = 3.99\n",
    "            for _ in range(length):\n",
    "                x = r * x * (1 - x)\n",
    "                sequence.append(2 * x - 1)  # Map to [-1, 1]\n",
    "            return np.array(sequence)\n",
    "            \n",
    "        elif self.chaotic_map == 'tent':\n",
    "            # Tent map\n",
    "            sequence = []\n",
    "            x = 0.1 + seed * 0.01\n",
    "            for _ in range(length):\n",
    "                if x < 0.5:\n",
    "                    x = 2 * x\n",
    "                else:\n",
    "                    x = 2 * (1 - x)\n",
    "                sequence.append(2 * x - 1)\n",
    "            return np.array(sequence)\n",
    "            \n",
    "        elif self.chaotic_map == 'bernoulli':\n",
    "            # Bernoulli-like from chaotic behavior\n",
    "            sequence = []\n",
    "            x = 0.1 + seed * 0.01\n",
    "            r = 3.99\n",
    "            for _ in range(length):\n",
    "                x = r * x * (1 - x)\n",
    "                sequence.append(1 if x > 0.5 else -1)\n",
    "            return np.array(sequence)\n",
    "            \n",
    "        elif self.chaotic_map == 'chebyshev':\n",
    "            # Chebyshev map\n",
    "            sequence = []\n",
    "            x = 0.1 + seed * 0.01\n",
    "            k = 4\n",
    "            for _ in range(length):\n",
    "                x = np.cos(k * np.arccos(x))\n",
    "                sequence.append(x)\n",
    "            return np.array(sequence)\n",
    "        \n",
    "        else:\n",
    "            return np.random.randn(length)\n",
    "    \n",
    "    def block_chaotic_compression(self, audio_data, level=4):\n",
    "        \"\"\"Block-based compression that never stores full matrix\"\"\"\n",
    "        print(f\"\\nüéµ Applying {self.chaotic_map.upper()} Chaotic Compression...\")\n",
    "        \n",
    "        # Use appropriate DWT level\n",
    "        max_possible_level = pywt.dwt_max_level(len(audio_data), self.wavelet)\n",
    "        level = min(level, max_possible_level, 4)  # Reduced level for stability\n",
    "        \n",
    "        print(f\"   DWT level: {level}\")\n",
    "        coeffs = pywt.wavedec(audio_data, self.wavelet, level=level)\n",
    "        coeffs_flat = np.concatenate(coeffs)\n",
    "        N = len(coeffs_flat)\n",
    "        M = int(N * self.compression_ratio)\n",
    "        \n",
    "        print(f\"   Coefficients: {N} ‚Üí {M} (Compression: {M/N:.1%})\")\n",
    "        \n",
    "        # Block processing - generate chaotic vectors on the fly\n",
    "        compressed_coeffs = np.zeros(M)\n",
    "        block_size = 1000  # Process 1000 measurements at a time\n",
    "        \n",
    "        print(\"   Block compression progress:\")\n",
    "        for i in range(0, M, block_size):\n",
    "            end_idx = min(i + block_size, M)\n",
    "            current_block_size = end_idx - i\n",
    "            \n",
    "            # Generate chaotic vectors for this block\n",
    "            block_measurements = np.zeros(current_block_size)\n",
    "            \n",
    "            for j in range(current_block_size):\n",
    "                # Generate chaotic measurement vector for this row\n",
    "                chaotic_vector = self.generate_chaotic_vector(N, seed=i+j)\n",
    "                # Dot product with coefficients\n",
    "                block_measurements[j] = np.dot(chaotic_vector, coeffs_flat)\n",
    "            \n",
    "            compressed_coeffs[i:end_idx] = block_measurements\n",
    "            \n",
    "            if (i // block_size) % 5 == 0:\n",
    "                print(f\"      {min(i+block_size, M)}/{M} measurements completed\")\n",
    "        \n",
    "        return compressed_coeffs, coeffs, N, M\n",
    "    \n",
    "    def block_chaotic_reconstruction(self, compressed_coeffs, original_coeff_length, method='gradient'):\n",
    "        \"\"\"Reconstruct using block-based approach\"\"\"\n",
    "        print(f\"   Reconstruction using {method} method...\")\n",
    "        \n",
    "        M = len(compressed_coeffs)\n",
    "        N = original_coeff_length\n",
    "        \n",
    "        if method == 'gradient':\n",
    "            # Gradient descent reconstruction\n",
    "            x_reconstructed = np.zeros(N)\n",
    "            learning_rate = 0.01\n",
    "            num_iterations = 20\n",
    "            \n",
    "            for iteration in range(num_iterations):\n",
    "                gradient = np.zeros(N)\n",
    "                \n",
    "                # Compute gradient in blocks\n",
    "                block_size = 500\n",
    "                for i in range(0, M, block_size):\n",
    "                    end_idx = min(i + block_size, M)\n",
    "                    current_block_size = end_idx - i\n",
    "                    \n",
    "                    for j in range(current_block_size):\n",
    "                        chaotic_vector = self.generate_chaotic_vector(N, seed=i+j)\n",
    "                        y_pred = np.dot(chaotic_vector, x_reconstructed)\n",
    "                        error = compressed_coeffs[i+j] - y_pred\n",
    "                        gradient += error * chaotic_vector\n",
    "                \n",
    "                # Update\n",
    "                x_reconstructed += learning_rate * gradient / M\n",
    "                \n",
    "                if iteration % 5 == 0:\n",
    "                    error_norm = np.linalg.norm(gradient) / M\n",
    "                    print(f\"      Iteration {iteration+1}/{num_iterations}, Error: {error_norm:.6f}\")\n",
    "        \n",
    "        elif method == 'simple':\n",
    "            # Simple pseudo-inverse approximation\n",
    "            x_reconstructed = np.zeros(N)\n",
    "            block_size = 1000\n",
    "            \n",
    "            for i in range(0, M, block_size):\n",
    "                end_idx = min(i + block_size, M)\n",
    "                current_block_size = end_idx - i\n",
    "                \n",
    "                # Generate block matrix temporarily\n",
    "                block_matrix = np.zeros((current_block_size, N))\n",
    "                for j in range(current_block_size):\n",
    "                    block_matrix[j] = self.generate_chaotic_vector(N, seed=i+j)\n",
    "                \n",
    "                # Partial reconstruction\n",
    "                block_measurements = compressed_coeffs[i:end_idx]\n",
    "                block_reconstruction = np.linalg.lstsq(block_matrix, block_measurements, rcond=None)[0]\n",
    "                x_reconstructed += block_reconstruction / (M // block_size)\n",
    "        \n",
    "        return x_reconstructed\n",
    "    \n",
    "    def reconstruct_audio(self, compressed_coeffs, original_coeff_length, level=4):\n",
    "        \"\"\"Full audio reconstruction pipeline\"\"\"\n",
    "        # Reconstruct coefficients\n",
    "        coeffs_reconstructed_flat = self.block_chaotic_reconstruction(\n",
    "            compressed_coeffs, original_coeff_length, method='gradient'\n",
    "        )\n",
    "        \n",
    "        # Reconstruct DWT coefficient structure\n",
    "        coeffs_reconstructed = []\n",
    "        start_idx = 0\n",
    "        coeffs_slices = pywt.wavedec(np.zeros(original_coeff_length), self.wavelet, level=level)\n",
    "        \n",
    "        for coeff in coeffs_slices:\n",
    "            end_idx = start_idx + len(coeff)\n",
    "            if end_idx <= len(coeffs_reconstructed_flat):\n",
    "                coeff_reconstructed = coeffs_reconstructed_flat[start_idx:end_idx]\n",
    "                coeffs_reconstructed.append(coeff_reconstructed)\n",
    "                start_idx = end_idx\n",
    "        \n",
    "        # Apply inverse DWT\n",
    "        reconstructed_audio = pywt.waverec(coeffs_reconstructed, self.wavelet)\n",
    "        \n",
    "        return reconstructed_audio\n",
    "    \n",
    "    def calculate_metrics(self, original, reconstructed):\n",
    "        \"\"\"Calculate comprehensive quality metrics\"\"\"\n",
    "        min_len = min(len(original), len(reconstructed))\n",
    "        original_trimmed = original[:min_len]\n",
    "        reconstructed_trimmed = reconstructed[:min_len]\n",
    "        \n",
    "        # MSE and SNR\n",
    "        mse = np.mean((original_trimmed - reconstructed_trimmed)**2)\n",
    "        snr = 10 * np.log10(np.var(original_trimmed) / (mse + 1e-10))\n",
    "        \n",
    "        # Additional metrics\n",
    "        correlation = np.corrcoef(original_trimmed, reconstructed_trimmed)[0, 1]\n",
    "        max_error = np.max(np.abs(original_trimmed - reconstructed_trimmed))\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'snr': snr,\n",
    "            'correlation': correlation,\n",
    "            'max_error': max_error\n",
    "        }\n",
    "\n",
    "def efficient_chaotic_comparison(wav_file_path):\n",
    "    \"\"\"Memory-efficient comparison of chaotic maps\"\"\"\n",
    "    \n",
    "    if not os.path.exists(wav_file_path):\n",
    "        print(f\"‚ùå File '{wav_file_path}' not found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üéµ Loading: {wav_file_path}\")\n",
    "    \n",
    "    # Load with shorter duration for stability\n",
    "    audio_data, sample_rate = librosa.load(wav_file_path, sr=None, mono=True, duration=2)\n",
    "    audio_data = audio_data / np.max(np.abs(audio_data))\n",
    "    \n",
    "    print(f\"üìä Processing: {len(audio_data)} samples, {sample_rate} Hz\")\n",
    "    \n",
    "    # Test chaotic maps\n",
    "    chaotic_maps = ['logistic', 'tent', 'bernoulli', 'chebyshev']\n",
    "    results = {}\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, chaotic_map in enumerate(chaotic_maps):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üß™ Testing {chaotic_map.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Initialize compressor\n",
    "            compressor = BlockChaoticDWTCompressedSensing(\n",
    "                wavelet='db4',\n",
    "                compression_ratio=0.5, \n",
    "                chaotic_map=chaotic_map\n",
    "            )\n",
    "            \n",
    "            # Apply compression\n",
    "            compressed_data, coeffs, N, M = compressor.block_chaotic_compression(audio_data)\n",
    "            \n",
    "            # Reconstruct\n",
    "            reconstructed = compressor.reconstruct_audio(compressed_data, N)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            min_len = min(len(audio_data), len(reconstructed))\n",
    "            metrics = compressor.calculate_metrics(\n",
    "                audio_data[:min_len], \n",
    "                reconstructed[:min_len]\n",
    "            )\n",
    "            \n",
    "            results[chaotic_map] = {\n",
    "                'reconstructed': reconstructed[:min_len],\n",
    "                'metrics': metrics,\n",
    "                'compression_ratio': M/N\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ {chaotic_map.upper()} Results:\")\n",
    "            print(f\"   - SNR: {metrics['snr']:.2f} dB\")\n",
    "            print(f\"   - MSE: {metrics['mse']:.6f}\")\n",
    "            print(f\"   - Correlation: {metrics['correlation']:.4f}\")\n",
    "            print(f\"   - Max Error: {metrics['max_error']:.6f}\")\n",
    "            \n",
    "            # Plot time domain comparison\n",
    "            plt.subplot(2, 2, idx+1)\n",
    "            time_axis = np.arange(min_len) / sample_rate\n",
    "            \n",
    "            # Plot first second\n",
    "            plot_samples = min(int(1.0 * sample_rate), min_len)\n",
    "            plt.plot(time_axis[:plot_samples], audio_data[:plot_samples], \n",
    "                    'b-', alpha=0.8, label='Original', linewidth=1.5)\n",
    "            plt.plot(time_axis[:plot_samples], reconstructed[:plot_samples], \n",
    "                    'r-', alpha=0.7, label='Reconstructed', linewidth=1)\n",
    "            plt.title(f'{chaotic_map.upper()}\\nSNR: {metrics[\"snr\"]:.1f} dB')\n",
    "            plt.xlabel('Time (s)')\n",
    "            plt.ylabel('Amplitude')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error with {chaotic_map}: {str(e)[:100]}...\")\n",
    "            results[chaotic_map] = None\n",
    "    \n",
    "    # Plot comparison summary\n",
    "    successful_results = {k: v for k, v in results.items() if v is not None}\n",
    "    \n",
    "    if successful_results:\n",
    "        # Metrics comparison plot\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        maps = list(successful_results.keys())\n",
    "        snr_values = [result['metrics']['snr'] for result in successful_results.values()]\n",
    "        mse_values = [result['metrics']['mse'] for result in successful_results.values()]\n",
    "        corr_values = [result['metrics']['correlation'] for result in successful_results.values()]\n",
    "        max_err_values = [result['metrics']['max_error'] for result in successful_results.values()]\n",
    "        \n",
    "        # SNR comparison\n",
    "        bars1 = ax1.bar(maps, snr_values, color='lightblue', alpha=0.7)\n",
    "        ax1.set_title('SNR Comparison (Higher is Better)')\n",
    "        ax1.set_ylabel('SNR (dB)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        for bar, value in zip(bars1, snr_values):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{value:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        # MSE comparison\n",
    "        bars2 = ax2.bar(maps, mse_values, color='lightcoral', alpha=0.7)\n",
    "        ax2.set_title('MSE Comparison (Lower is Better)')\n",
    "        ax2.set_ylabel('MSE')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        for bar, value in zip(bars2, mse_values):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.0001,\n",
    "                    f'{value:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Correlation comparison\n",
    "        bars3 = ax3.bar(maps, corr_values, color='lightgreen', alpha=0.7)\n",
    "        ax3.set_title('Correlation Comparison (Higher is Better)')\n",
    "        ax3.set_ylabel('Correlation Coefficient')\n",
    "        ax3.set_ylim(0, 1)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        for bar, value in zip(bars3, corr_values):\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Max Error comparison\n",
    "        bars4 = ax4.bar(maps, max_err_values, color='lightyellow', alpha=0.7)\n",
    "        ax4.set_title('Max Error Comparison (Lower is Better)')\n",
    "        ax4.set_ylabel('Max Error')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        for bar, value in zip(bars4, max_err_values):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print results summary\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üìä FINAL RESULTS SUMMARY\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        best_snr = max(successful_results.items(), key=lambda x: x[1]['metrics']['snr'])\n",
    "        best_mse = min(successful_results.items(), key=lambda x: x[1]['metrics']['mse'])\n",
    "        \n",
    "        print(f\"üèÜ BEST PERFORMANCE:\")\n",
    "        print(f\"   Highest SNR: {best_snr[0].upper()} ({best_snr[1]['metrics']['snr']:.2f} dB)\")\n",
    "        print(f\"   Lowest MSE:  {best_mse[0].upper()} ({best_mse[1]['metrics']['mse']:.6f})\")\n",
    "        \n",
    "        print(f\"\\nüìà DETAILED RESULTS:\")\n",
    "        print(f\"{'Map':<12} | {'SNR (dB)':<8} | {'MSE':<10} | {'Correlation':<10} | {'Max Error':<10}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "        for map_name, result in successful_results.items():\n",
    "            metrics = result['metrics']\n",
    "            print(f\"{map_name.upper():<12} | {metrics['snr']:>8.2f} | {metrics['mse']:>10.6f} | \"\n",
    "                  f\"{metrics['correlation']:>10.4f} | {metrics['max_error']:>10.6f}\")\n",
    "        \n",
    "        # Save best result\n",
    "        best_method = best_snr[0]\n",
    "        best_audio = successful_results[best_method]['reconstructed']\n",
    "        \n",
    "        output_dir = 'chaotic_compression_results'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        original_filename = os.path.splitext(os.path.basename(wav_file_path))[0]\n",
    "        \n",
    "        wavfile.write(f'{output_dir}/{original_filename}_original.wav', sample_rate,\n",
    "                     np.int16(audio_data * 32767))\n",
    "        wavfile.write(f'{output_dir}/{original_filename}_{best_method}_best.wav', sample_rate,\n",
    "                     np.int16(best_audio * 32767))\n",
    "        \n",
    "        print(f\"\\nüíæ Saved best result ({best_method.upper()}) to '{output_dir}' folder\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# **üéØ MAIN EXECUTION üéØ**\n",
    "if __name__ == \"__main__\":\n",
    "    # ==============================================\n",
    "    # üîΩ PUT YOUR WAV FILE PATH HERE üîΩ\n",
    "    # ==============================================\n",
    "    YOUR_WAV_FILE_PATH = \"UrbanSound8K/any_wav.wav\"  # ‚¨ÖÔ∏è CHANGE THIS!\n",
    "    # ==============================================\n",
    "    \n",
    "    print(\"üöÄ Starting Memory-Efficient Chaotic Map Comparison...\")\n",
    "    print(\"üí° Using block processing to avoid memory issues...\")\n",
    "    \n",
    "    results = efficient_chaotic_comparison(YOUR_WAV_FILE_PATH)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Chaotic Map Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722aff7f-886e-45dc-ab02-8df1e9943a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
