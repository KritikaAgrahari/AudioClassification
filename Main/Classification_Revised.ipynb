{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f34e46-4a8a-493f-99c5-5a9674a8645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7e607e6-d498-43d2-8ebc-3d7aa08470e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b27fc8-81ab-473b-a535-e56ed1af0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ENHANCED FEATURE EXTRACTION FUNCTION\n",
    "def extract_features(file_path, n_mfcc=40, n_mels=128, n_chroma=12):\n",
    "    \"\"\"\n",
    "    Extract multiple audio features for better representation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # 1. MFCCs (Mel-frequency cepstral coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "        mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "        features.extend(mfccs_scaled)\n",
    "        \n",
    "        # 2. Mel Spectrogram\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "        mel_scaled = np.mean(mel_spec.T, axis=0)\n",
    "        features.extend(mel_scaled)\n",
    "        \n",
    "        # 3. Chroma Features\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate, n_chroma=n_chroma)\n",
    "        chroma_scaled = np.mean(chroma.T, axis=0)\n",
    "        features.extend(chroma_scaled)\n",
    "        \n",
    "        # 4. Spectral Contrast\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n",
    "        spectral_scaled = np.mean(spectral_contrast.T, axis=0)\n",
    "        features.extend(spectral_scaled)\n",
    "        \n",
    "        # 5. Zero Crossing Rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio)\n",
    "        zcr_scaled = np.mean(zcr)\n",
    "        features.append(zcr_scaled)\n",
    "        \n",
    "        # 6. RMS Energy\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        rms_scaled = np.mean(rms)\n",
    "        features.append(rms_scaled)\n",
    "        \n",
    "        # 7. Spectral Centroid\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sample_rate)\n",
    "        centroid_scaled = np.mean(spectral_centroid)\n",
    "        features.append(centroid_scaled)\n",
    "        \n",
    "        # 8. Spectral Bandwidth\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sample_rate)\n",
    "        bandwidth_scaled = np.mean(spectral_bandwidth)\n",
    "        features.append(bandwidth_scaled)\n",
    "        \n",
    "        # 9. Spectral Roll-off\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sample_rate)\n",
    "        rolloff_scaled = np.mean(spectral_rolloff)\n",
    "        features.append(rolloff_scaled)\n",
    "        \n",
    "        # 10. Harmonic and Percussive components\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(audio)\n",
    "        harmonic_scaled = np.mean(y_harmonic)\n",
    "        percussive_scaled = np.mean(y_percussive)\n",
    "        features.extend([harmonic_scaled, percussive_scaled])\n",
    "        \n",
    "        # 11. Tempogram (for rhythmic features)\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sample_rate)\n",
    "        tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sample_rate)\n",
    "        features.append(tempo[0])\n",
    "        \n",
    "        return np.array(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86397e89-efd6-4cea-9351-9607c1f21fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. IMPROVED DATA LOADING WITH AUGMENTATION\n",
    "def load_and_preprocess_data(base_path, metadata_file='UrbanSound8K/metadata/UrbanSound8K.csv'):\n",
    "    \"\"\"\n",
    "    Load UrbanSound8K dataset with optional data augmentation\n",
    "    \"\"\"\n",
    "    # Load metadata\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Loading and extracting features...\")\n",
    "    \n",
    "    for idx, row in metadata.iterrows():\n",
    "        # Construct file path\n",
    "        fold = row['fold']\n",
    "        filename = row['slice_file_name']\n",
    "        file_path = f\"{base_path}/fold{fold}/{filename}\"\n",
    "        \n",
    "        # Extract features from original audio\n",
    "        feature = extract_features(file_path)\n",
    "        \n",
    "        if feature is not None:\n",
    "            features.append(feature)\n",
    "            labels.append(row['class'])\n",
    "            \n",
    "            # DATA AUGMENTATION - Add variations\n",
    "            try:\n",
    "                audio, sr = librosa.load(file_path, sr=None)\n",
    "                \n",
    "                # Augmentation 1: Add noise\n",
    "                noise = np.random.randn(len(audio)) * 0.005\n",
    "                audio_noisy = audio + noise\n",
    "                temp_path = \"temp_aug.wav\"\n",
    "                librosa.output.write_wav(temp_path, audio_noisy, sr)\n",
    "                feature_noisy = extract_features(temp_path)\n",
    "                if feature_noisy is not None:\n",
    "                    features.append(feature_noisy)\n",
    "                    labels.append(row['class'])\n",
    "                \n",
    "                # Augmentation 2: Time stretching\n",
    "                audio_stretched = librosa.effects.time_stretch(audio, rate=0.9)\n",
    "                librosa.output.write_wav(temp_path, audio_stretched, sr)\n",
    "                feature_stretched = extract_features(temp_path)\n",
    "                if feature_stretched is not None:\n",
    "                    features.append(feature_stretched)\n",
    "                    labels.append(row['class'])\n",
    "                \n",
    "                # Augmentation 3: Pitch shifting\n",
    "                audio_pitch = librosa.effects.pitch_shift(audio, sr, n_steps=2)\n",
    "                librosa.output.write_wav(temp_path, audio_pitch, sr)\n",
    "                feature_pitch = extract_features(temp_path)\n",
    "                if feature_pitch is not None:\n",
    "                    features.append(feature_pitch)\n",
    "                    labels.append(row['class'])\n",
    "                    \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc86db86-e0cf-4124-99b2-85fea66c07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ENHANCED NEURAL NETWORK ARCHITECTURE\n",
    "def create_enhanced_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a more sophisticated neural network model\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        \n",
    "        # Batch Normalization for faster convergence\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # First Dense block with dropout\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Second Dense block\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Third Dense block\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Fourth Dense block\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile with different optimizers to find best one\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0005,  # Lower learning rate\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31a2674-1c93-444d-9309-3b1dc8a12739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CREATE CNN MODEL FOR SPECTROGRAM IMAGES (Alternative approach)\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CNN model for spectrogram images\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Convolutional layers\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 5. ENSEMBLE MODEL (Combines multiple models)\n",
    "class EnsembleModel:\n",
    "    def __init__(self, models_list):\n",
    "        self.models = models_list\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict(X)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Average predictions\n",
    "        avg_predictions = np.mean(predictions, axis=0)\n",
    "        return np.argmax(avg_predictions, axis=1)\n",
    "\n",
    "# 6. CALLBACKS FOR BETTER TRAINING\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997c0582-557e-4def-b2a4-df02718532d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. MAIN TRAINING PIPELINE\n",
    "def main():\n",
    "    # Set base path\n",
    "    base_path = \"UrbanSound8K/audio\"\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Step 1: Loading data...\")\n",
    "    X, y = load_and_preprocess_data(base_path)\n",
    "    \n",
    "    # Encode labels\n",
    "    print(\"Step 2: Encoding labels...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "    \n",
    "    # Split data\n",
    "    print(\"Step 3: Splitting data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_categorical, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    print(\"Step 4: Standardizing features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Create and train model\n",
    "    print(\"Step 5: Creating model...\")\n",
    "    input_shape = X_train.shape[1]\n",
    "    num_classes = len(np.unique(y_encoded))\n",
    "    \n",
    "    model = create_enhanced_model(input_shape, num_classes)\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Step 6: Training model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=get_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(\"Step 7: Evaluating model...\")\n",
    "    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes, \n",
    "                                target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    axes[0, 1].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision')\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall')\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, scaler, label_encoder, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0737e867-12c7-4f2d-86b3-6c7986915376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. HYPERPARAMETER TUNING FUNCTION\n",
    "def hyperparameter_tuning(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning (simplified version)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "    \n",
    "    def create_model(learning_rate=0.001, dropout_rate=0.3):\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(y_train.shape[1], activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer,\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    \n",
    "    param_grid = {\n",
    "        'batch_size': [16, 32, 64],\n",
    "        'epochs': [50, 100],\n",
    "        'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "        'dropout_rate': [0.2, 0.3, 0.4]\n",
    "    }\n",
    "    \n",
    "    # Note: This can be computationally expensive\n",
    "    print(\"Hyperparameter tuning might take a while...\")\n",
    "    # grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "    # grid_result = grid.fit(X_train, y_train)\n",
    "    \n",
    "    # print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c029c-de3a-435e-a3ae-07e73c4b29d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading data...\n",
      "Loading and extracting features...\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    model, scaler, label_encoder, history = main()\n",
    "    \n",
    "    # Save the model\n",
    "    model.save('saved_models/urban_sound_classifier.h5')\n",
    "    print(\"\\nModel saved as 'saved_models/urban_sound_classifier.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a382f0-8535-4686-90d0-2360ebe749b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
